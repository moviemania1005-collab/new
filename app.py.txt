"""
Single-file project: train models + Streamlit app
File: app.py

Usage:
- Train models and save best pipeline:
python app.py --train
- Start Streamlit app:
streamlit run app.py
"""

import os
import sys
import json
import argparse
from io import BytesIO
from zipfile import ZipFile

import pandas as pd
import numpy as np
import requests
import joblib

# ML imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# For plotting in streamlit
try:
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
except Exception:
# Streamlit may not be installed in train-only environment, that's fine
st = None

# Directories
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(ROOT_DIR, "data")
MODELS_DIR = os.path.join(ROOT_DIR, "models")
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

UCI_BASE = "https://archive.ics.uci.edu/ml/machine-learning-databases/00320/"
DEFAULT_CSV = "student-mat.csv" # mathematics dataset; change to student-por.csv if needed

########################
# Data utilities
########################
def download_if_missing(filename=DEFAULT_CSV):
"""Download student.zip from UCI and extract requested CSV if not present."""
target_path = os.path.join(DATA_DIR, filename)
if os.path.exists(target_path):
print(f"[data] {filename} already exists at {target_path}")
return target_path

print("[data] Downloading dataset from UCI...")
zip_url = UCI_BASE + "student.zip"
resp = requests.get(zip_url, timeout=30)
resp.raise_for_status()
z = ZipFile(BytesIO(resp.content))
candidates = [name for name in z.namelist() if name.endswith(filename)]
if not candidates:
raise FileNotFoundError(f"{filename} not found in UCI zip.")
z.extract(candidates[0], path=DATA_DIR)
extracted = os.path.join(DATA_DIR, candidates[0])
final_path = os.path.join(DATA_DIR, filename)
if extracted != final_path:
os.replace(extracted, final_path)
print(f"[data] Saved dataset to {final_path}")
return final_path

def load_data(filename=DEFAULT_CSV):
path = download_if_missing(filename)
df = pd.read_csv(path, sep=';')
return df

########################
# Preprocessing
########################
def label_performance(g3):
# Map final grade to categories
if g3 < 10:
return "Low"
elif g3 < 15:
return "Medium"
else:
return "High"

def prepare_dataframe(df, drop_cols=None):
df = df.copy()
# create target
df['performance'] = df['G3'].apply(label_performance)
# drop G3 (target) and any extra drop_cols
drop_cols = drop_cols or []
cols_to_drop = ['G3'] + drop_cols
df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')
return df

def get_feature_lists(df):
# infer numeric and categorical features
categorical = df.select_dtypes(include=['object', 'category']).columns.tolist()
numeric = df.select_dtypes(include=[np.number]).columns.tolist()
# remove target if present
if 'performance' in categorical:
categorical.remove('performance')
if 'performance' in numeric:
numeric.remove('performance')
return categorical, numeric

def build_preprocessor(df):
cat_cols, num_cols = get_feature_lists(df)
# numeric scaling, categorical one-hot encoding
numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])
categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])
preprocessor = ColumnTransformer(transformers=[
('num', numeric_transformer, num_cols),
('cat', categorical_transformer, cat_cols)
], remainder='drop')
return preprocessor

########################
# Training pipeline
########################
def train_and_select(df, random_state=42, test_size=0.30):
"""
Train DecisionTree, RandomForest, SVM and select best by accuracy on hold-out test set.
Returns: dict with results and best pipeline saved to disk.
"""
df_proc = prepare_dataframe(df)
X = df_proc.drop(columns=['performance'])
y = df_proc['performance']

X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=test_size, random_state=random_state, stratify=y
)

preprocessor = build_preprocessor(X_train)

# models to try
candidates = {
"DecisionTree": DecisionTreeClassifier(random_state=random_state, max_depth=7),
"RandomForest": RandomForestClassifier(random_state=random_state, n_estimators=200),
"SVM": SVC(kernel='rbf', probability=True, random_state=random_state)
}

results = {}
for name, clf in candidates.items():
print(f"[train] Training {name} ...")
pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', clf)])
pipe.fit(X_train, y_train)
preds = pipe.predict(X_test)
acc = accuracy_score(y_test, preds)
report = classification_report(y_test, preds, output_dict=True)
cm = confusion_matrix(y_test, preds, labels=pipe.classes_)
results[name] = {
"pipeline": pipe,
"accuracy": float(acc),
"report": report,
"confusion_matrix": cm.tolist(),
"classes": pipe.classes_.tolist()
}
print(f"[train] {name} accuracy: {acc:.4f}")

# select best by accuracy
best_name = max(results.keys(), key=lambda k: results[k]['accuracy'])
best = results[best_name]
print(f"[train] Best model: {best_name} (accuracy={best['accuracy']:.4f})")

# Save best pipeline
model_path = os.path.join(MODELS_DIR, "best_pipeline.joblib")
joblib.dump(best['pipeline'], model_path)
print(f"[train] Saved best pipeline to {model_path}")

# Save metrics
metrics_path = os.path.join(MODELS_DIR, "metrics_report.json")
with open(metrics_path, "w") as f:
json.dump({k: {"accuracy": v["accuracy"], "report": v["report"], "classes": v["classes"]} for k, v in results.items()}, f, indent=2)
print(f"[train] Saved metrics to {metrics_path}")

return best_name, results

########################
# Prediction utility
########################
def load_pipeline(path=None):
path = path or os.path.join(MODELS_DIR, "best_pipeline.joblib")
if not os.path.exists(path):
raise FileNotFoundError(f"Pipeline not found at {path}. Train first with --train.")
return joblib.load(path)

def predict_single(pipeline, sample_dict):
df = pd.DataFrame([sample_dict])
pred = pipeline.predict(df)[0]
prob = None
if hasattr(pipeline, "predict_proba"):
prob = pipeline.predict_proba(df)[0].tolist()
classes = pipeline.classes_.tolist()
else:
classes = pipeline.classes_.tolist()
return {"prediction": pred, "probabilities": prob, "classes": classes}

########################
# Streamlit app
########################
def run_streamlit_app():
if st is None:
raise RuntimeError("Streamlit is not available. Install streamlit to run the app: pip install streamlit")

st.set_page_config(page_title="Student Performance Predictor", layout="wide")
st.title("Predictive Analysis of Student Academic Performance")
st.markdown("Machine learning model predicts student performance category (Low / Medium / High).")

# Load dataset and pipeline
with st.spinner("Loading data and model..."):
df = load_data()
df_proc = prepare_dataframe(df)
pipeline = None
try:
pipeline = load_pipeline()
except Exception as e:
st.warning("Model pipeline not found. Please train first by running `python app.py --train`")
pipeline = None

st.sidebar.header("Controls")
mode = st.sidebar.radio("Mode", ("Predict Single Student", "Dataset & Model Info"))

if mode == "Predict Single Student":
st.sidebar.markdown("Enter student attributes (defaults from dataset).")
# build form using dataset columns (excluding 'performance')
example = df_proc.drop(columns=['performance']).iloc[0].to_dict()
user_input = {}
for col, val in example.items():
if pd.api.types.is_integer_dtype(type(val)) or pd.api.types.is_float_dtype(type(val)):
# use min/max from dataset
mn = int(df[col].min()) if np.issubdtype(df[col].dtype, np.number) else 0
mx = int(df[col].max()) if np.issubdtype(df[col].dtype, np.number) else 100
user_input[col] = st.sidebar.number_input(col, min_value=mn, max_value=mx, value=int(val))
else:
opts = sorted(df[col].unique().tolist())
user_input[col] = st.sidebar.selectbox(col, opts, index=opts.index(val) if val in opts else 0)

if st.sidebar.button("Predict"):
if pipeline is None:
st.error("No trained model available. Run training first.")
else:
res = predict_single(pipeline, user_input)
st.subheader("Prediction")
st.write(f"**Predicted class:** {res['prediction']}")
if res['probabilities'] is not None:
st.write("**Probabilities:**")
proba_map = {cls: f"{p:.3f}" for cls, p in zip(res['classes'], res['probabilities'])}
st.json(proba_map)

else:
st.header("Dataset overview")
st.write("Sample rows from dataset:")
st.dataframe(df.head(10))

st.subheader("Feature distributions (select feature)")
# numeric columns for histogram
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
sel = st.selectbox("Select numeric column", numeric_cols)
fig, ax = plt.subplots()
sns.histplot(df[sel], kde=True, ax=ax)
st.pyplot(fig)

st.subheader("Model performance")
metrics_path = os.path.join(MODELS_DIR, "metrics_report.json")
if os.path.exists(metrics_path):
with open(metrics_path, "r") as f:
metrics = json.load(f)
accs = {k: v["accuracy"] for k, v in metrics.items()}
acc_df = pd.DataFrame(list(accs.items()), columns=["Model", "Accuracy"]).set_index("Model")
st.bar_chart(acc_df)

st.write("Detailed classification reports:")
for model_name, info in metrics.items():
st.markdown(f"**{model_name}** (accuracy={info['accuracy']:.3f})")
st.json(info['report'])
else:
st.info("No metrics file found. Train the models using `python app.py --train`")

if pipeline is not None:
st.subheader("Confusion matrix on whole dataset (proxy)")
proc_df = prepare_dataframe(df)
X_all = proc_df.drop(columns=['performance'])
y_all = proc_df['performance']
preds = pipeline.predict(X_all)
cm = confusion_matrix(y_all, preds, labels=pipeline.classes_)
fig2, ax2 = plt.subplots()
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_, ax=ax2)
ax2.set_xlabel("Predicted")
ax2.set_ylabel("Actual")
st.pyplot(fig2)

st.markdown("---")
st.write("Notes: This app uses an offline model saved to the `models` directory. For production use, ensure appropriate data privacy and governance.")

########################
# CLI / main
########################
def main():
parser = argparse.ArgumentParser(description="Student performance ML + Streamlit app (single file).")
parser.add_argument("--train", action="store_true", help="Train models and save best pipeline.")
parser.add_argument("--csv", type=str, default=DEFAULT_CSV, help="CSV filename to use from UCI zip (student-mat.csv or student-por.csv).")
args = parser.parse_args()

if args.train:
print("[main] Starting training pipeline...")
df = load_data(args.csv)
best_name, results = train_and_select(df)
print(f"[main] Training complete. Best model: {best_name}")
print("[main] You can now run: streamlit run app.py")
else:
# If script called under Streamlit, this code still runs inside streamlit process.
# Start Streamlit UI if st is available, else show message.
if "streamlit" in sys.argv[0] or st is not None:
# Running via streamlit run => launch app
run_streamlit_app()
else:
print("No --train flag given. To train models run: python app.py --train")
print("To run the Streamlit UI: streamlit run app.py")

if __name__ == "__main__":
main()
